# Team-Project-13

### Idea-1: Wildfire Prediction in the US 


* Introduction <br>

Wildfires in the US have had a major impact, not only on the air quality, but also on global climate change because burning plants and trees releases planet-warming CO2. The wildfire season is starting early and ending late each year. Through this project, we hope to build a predictive model that leverages the data collected from all over the country consisting of about 1.88 Million instances of wildfires.

* Abstract <br>

In this project, we aim to develop a tool that uses this data and predicts the impact of wildfires in terms of damage done in size based on a variety of factors like state, county, exact geographical location, etc. This insight can then be used by a number of people to make informed decisions on prevention and control of wildfires.

* Approach <br>

We would be doing Exploratory Data Analysis (EDA) to identify key characteristics and relationships that would help us develop a good machine learning model. We would also do data preprocessing tasks to ensure data quality. We would then train various models starting with a baseline model like Logistic Regression and then move on to more sophisticated ones like ensemble models and deep neural networks. The model that performs best would be chosen for making predictions.

* Persona <br> 

   * The fire department or a similar agency responsible for mitigating the fires can use this model to further aid their prevention and mitigation efforts.
   * Travel and campers enthusiasts can use this to identify potential wildfire zones before planning their roadtrips.
 
* Dataset links <br>

https://www.kaggle.com/rtatman/188-million-us-wildfires


### Idea-2: News Literacy

* Introduction <br>

According to the Radio Television Digital News Foundation, “News literacy is the acquisition of 21st-century, critical-thinking skills for analyzing and judging the reliability of news and information, differentiating among facts, opinions and assertions in the media we consume, create and distribute”. In this age where any type of news is readily available for anyone to use, we are often overwhelmed by the sheer amount of information that we consume. Having the skills to discern real news from fake is invaluable and through this project we attempt to develop a tool that aids people in this endeavor.

* Abstract <br>

Data collected through various sources like Kaggle will be used to train Machine Learning models. We plan to develop a tool that can take in unseen data and predict the credibility of that news.

* Approach <br>

We will be starting our analysis using the Fake News Dataset on Kaggle to perform preliminary processing and model training. We are planning to experiment with conventional Machine Learning models like:
  1. Support Vector Machine (SVM)
  2. Naive Bayes Classifier
  3. k-Nearest Neighbors(KNN) <br>
These will be first tokenized and converted into vectors using Bag-of-Words / TF-IDF first. We can also train the dataset using neural networks like Convolutional Neural Networks (CNN) and Long Short Term Memory networks (LSTMs) to improve the accuracy of predictions. We can have a presentation layer on top that uses the best performing model and try predicting the literacy of new, unseen and real-time news.

*  Persona <br>
    * Students and young people can be encouraged to use this tool to develop their critical thinking skills
    * Anyone who wishes to fact-check a piece of information found on the Internet

* Dataset <br>
 https://www.kaggle.com/c/fake-news/data?select=train.csv


